{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jJjRcvSg1c2Y"
   },
   "source": [
    "#Team\n",
    "#Chigozie Kenneth Okafor 225983\n",
    "#Md Khamar Uz Zama 226267\n",
    "#Rajatha Nagaraja Rao 223758"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXXv1Kl8tw0a"
   },
   "source": [
    "##SOURCE\n",
    "\n",
    "[Keras Tutorial](https://keras.io/examples/cifar10_cnn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v_pdYUzDtq3K",
    "outputId": "56952bdb-077b-4ac3-f591-78201f7c74c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBSrRM9AvJEX"
   },
   "outputs": [],
   "source": [
    "cifar100 = keras.datasets.cifar100\n",
    "cifar10 = keras.datasets.cifar10\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "\n",
    "\n",
    "train_labels = train_labels.reshape((-1,))\n",
    "test_labels = test_labels.reshape((-1,))\n",
    "\n",
    "# first difference: data is not reshaped to 784 anymore, but 28x28x1\n",
    "# note the 1 color channel!! this is important\n",
    "data = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, train_labels.astype(np.int32)))\n",
    "data = data.shuffle(buffer_size=60000).batch(128).repeat()\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (test_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, test_labels.astype(np.int32))).batch(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 838
    },
    "colab_type": "code",
    "id": "x7xHEGc58UEt",
    "outputId": "71e369f9-31c5-4d36-88d5-f494a3c8e824"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(train_labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3S5XA8gvn9F"
   },
   "outputs": [],
   "source": [
    "train_steps = 3000\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "\n",
    "\n",
    "\n",
    "def build_model(width, height, depth, classes):\n",
    "# initialize the input shape and channels dimension to be\n",
    "\t# \"channels last\" ordering\n",
    "\tinputShape = (height, width, depth)\n",
    "\tchanDim = -1\n",
    "\t# build the model using Keras' Sequential API\n",
    "\tmodel = tf.keras.Sequential([\n",
    "\t\t# CONV => RELU => BN => POOL layer set\n",
    "\t\tConv2D(16, (3, 3), padding=\"same\", input_shape=inputShape, kernel_initializer=initializer),\n",
    "\t\tActivation(\"elu\"),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 2 => POOL layer set\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"elu\"),\n",
    "\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\",  kernel_initializer=initializer),\n",
    "\t\tActivation(\"elu\"),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 3 => POOL layer set\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\",  kernel_initializer=initializer),\n",
    "\t\tActivation(\"elu\"),\n",
    "\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"elu\"),\n",
    "\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\",  kernel_initializer=initializer),\n",
    "\t\tActivation(\"elu\"),\n",
    "\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tFlatten(),\n",
    "\t\tDense(256),\n",
    "\t\tActivation(\"elu\"),\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tDense(classes),\n",
    "\t\t\n",
    "\t])\n",
    "\t# return the built model to the calling function\n",
    "\treturn model\n",
    "\n",
    "opt = tf.optimizers.Adam()\n",
    "# from_logits = True!! #neverforget\n",
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ylBYT2VuJYhB"
   },
   "source": [
    "Adam optimizer learns faster for this particular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "colab_type": "code",
    "id": "VqCp9eP_vs95",
    "outputId": "388b30f1-8549-4c17-f695-d668834445ff"
   },
   "outputs": [],
   "source": [
    "# this basically hasn't changed\n",
    "model = build_model(32, 32, 3, 10)\n",
    "\n",
    "for step, (img_batch, lbl_batch) in enumerate(data):\n",
    "\n",
    "    if step > train_steps:\n",
    "        break\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        img_batch = tf.image.per_image_standardization(img_batch)\n",
    "        logits = model(img_batch)\n",
    "        xent = loss_fn(lbl_batch, logits)\n",
    "\n",
    "    grads = tape.gradient(xent, model.trainable_variables)\n",
    "      \n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    \n",
    "    if not step % 100:\n",
    "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch),\n",
    "                             tf.float32))\n",
    "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CqWHkrHsvxoq",
    "outputId": "ee54c86d-5b00-4d0b-ede0-682c0322349d"
   },
   "outputs": [],
   "source": [
    "# here's some evaluation magic ;) bonus: figure out how this works...\n",
    "big_test_batch = next(iter(test_data))\n",
    "test_img = tf.image.per_image_standardization(big_test_batch[0])\n",
    "test_preds = tf.argmax(model(test_img), axis=1,\n",
    "                       output_type=tf.int32)\n",
    "\n",
    "test_labels = tf.reshape(big_test_batch[1], [-1])\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, test_labels),\n",
    "                             tf.float32))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "fWq0nZOeo2J7",
    "outputId": "fc73e916-e985-445f-e58d-851853e9567a"
   },
   "outputs": [],
   "source": [
    "#Change this to pick different layers in the sequential model ConvD 1, convD 2 as 0, 3, etc.... [0, 3, 5, 8, 9, 10, 12]\n",
    "Index_layer=0\n",
    "\n",
    "\n",
    "weights = model.layers[Index_layer].get_weights()[0][:,:,0,:]\n",
    "plt.title(\"Filters in Convolution layers\")\n",
    "for i in range(1,16):\n",
    "\n",
    "  plt.subplot(4,4,i)\n",
    "  plt.imshow(weights[:,:,i],interpolation=\"nearest\",cmap=\"gray\")\n",
    "# plt.title(\"Filters in Convolution layers\")  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "DRCjBO6q-ucA",
    "outputId": "57179464-1dce-443d-9e94-b495b22a81ef"
   },
   "outputs": [],
   "source": [
    "#pick an image from test data\n",
    "index = 0\n",
    "\n",
    "\n",
    "import cv2\n",
    "images = big_test_batch[0][index]\n",
    "images = images.numpy()\n",
    "img = np.squeeze(images)\n",
    "plt.imshow(img, cmap='gray')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## apply a specific set of filter weights (like the one displayed above) to the test image\n",
    "\n",
    "\n",
    "pick_filter = 8\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(15, 5))\n",
    "fig.add_subplot(2, 1, 1)\n",
    "plt.imshow(weights[:,:,pick_filter], cmap='gray')\n",
    "c = cv2.filter2D(img, -1, weights[:,:,pick_filter])\n",
    "fig.add_subplot(2, 2, 1)\n",
    "plt.imshow(c, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G43n4U6W2Sew"
   },
   "source": [
    "https://medium.com/octavian-ai/which-optimizer-and-learning-rate-should-i-use-for-deep-learning-5acb418f9b2 shows the optimal learning rates for different optimzers used on MNIST dataset; The learning rate was fixed to 0.0001 and the training duration to 3 epochs in this case, though.\n",
    "\n",
    "The used loss function was Sparse Categorical Cross-Entropy in every case\n",
    "\n",
    "*   Test accuracy  w. SGD ~ 82%\n",
    "*   Test accuracy  w. Adagrad ~ 84%\n",
    "*   Test accuracy  w. Adam ~ 90%\n",
    "*   Test accuracy  w. RMSProp ~ 90%\n",
    "\n",
    "Using the CIFAR10-dataset and the same general CNN-layout with the appropriate adjustments to the parameters e.g. channels and number of inputs, the accuracy values deterioriated markedly:\n",
    "\n",
    "*   Test accuracy  w. SGD ~ 48%\n",
    "*   Test accuracy  w. Adagrad ~ 32%\n",
    "*   Test accuracy  w. Adam ~ 70%\n",
    "*   Test accuracy  w. RMSProp ~ 69%\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Assigment_03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
