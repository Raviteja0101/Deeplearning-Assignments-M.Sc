{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "NPPcOicl7O9R",
    "outputId": "303650f0-667d-4c03-806d-9f17aa2d0d9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{':': 1, 'F': 2, 'm': 3, 'E': 4, 'N': 5, 'D': 6, 't': 7, '-': 8, '3': 9, 'o': 10, 'R': 11, 'Q': 12, 'e': 13, 'a': 14, 'd': 15, ';': 16, 'z': 17, 'K': 18, 'B': 19, 'W': 20, '?': 21, 'C': 22, 'n': 23, 'u': 24, 'I': 25, 'H': 26, '&': 27, '.': 28, 'S': 29, 'J': 30, 'c': 31, 'p': 32, 'A': 33, 'q': 34, '!': 35, 'T': 36, '[': 37, 'i': 38, 'r': 39, 'y': 40, ',': 41, 'M': 42, 'f': 43, '\\n': 44, 'j': 45, 'v': 46, 'h': 47, '$': 48, ']': 49, 'b': 50, 'U': 51, 's': 52, 'w': 53, 'P': 54, 'Y': 55, \"'\": 56, 'k': 57, 'g': 58, 'L': 59, 'x': 60, 'G': 61, 'V': 62, 'O': 63, ' ': 64, 'X': 65, 'Z': 66, 'l': 67, '<S>': 0}\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "##Loading preprocessed data skp.tfrecords & skp_vocab\n",
    "from prepare_data import parse_seq\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "bs = 256\n",
    "seq_len = 200\n",
    "# this is just a datasets of \"bytes\" (not understandable)\n",
    "data = tf.data.TFRecordDataset(\"skp.tfrecords\")\n",
    "\n",
    "# this maps a parser function that properly interprets the bytes over the dataset\n",
    "# (with fixed sequence length 200)\n",
    "# if you change the sequence length in preprocessing you also need to change it here\n",
    "data = data.map(lambda x: parse_seq(x, 200))\n",
    "\n",
    "# a map from characters to indices\n",
    "vocab = pickle.load(open(\"skp_vocab\", mode=\"rb\"))\n",
    "vocab_size = len(vocab)\n",
    "# inverse mapping: indices to characters\n",
    "ind_to_ch = {ind: ch for (ch, ind) in vocab.items()}\n",
    "\n",
    "print(vocab)\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBtnvr603oTP"
   },
   "outputs": [],
   "source": [
    "n_h = 512\n",
    "w_xh = tf.Variable(tf.initializers.glorot_uniform()([vocab_size, n_h]))\n",
    "w_hh = tf.Variable(tf.initializers.glorot_uniform()([n_h, n_h]))\n",
    "b_h = tf.Variable(tf.zeros([n_h]))\n",
    "\n",
    "w_ho = tf.Variable(tf.initializers.glorot_uniform()([n_h, vocab_size]))\n",
    "b_o = tf.Variable(tf.zeros([vocab_size]))\n",
    "\n",
    "all_vars = [w_xh, w_hh, b_h, w_ho, b_o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YaJG22L24WV2"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGadhB_H1Znn"
   },
   "outputs": [],
   "source": [
    "# training\n",
    "# somewhat arbitrary number of steps\n",
    "steps = 20*35000 // bs\n",
    "opt = tf.optimizers.Adam()\n",
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def run_rnn_on_seq(seq_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        state = tf.zeros([tf.shape(seq_batch)[0], n_h])\n",
    "        total_loss = tf.constant(0.)\n",
    "\n",
    "        for time_step in tf.range(tf.shape(seq_batch)[1] - 1):\n",
    "            inp_here = tf.one_hot(seq_batch[:, time_step], vocab_size)\n",
    "            state = tf.nn.tanh(tf.matmul(inp_here, w_xh) + tf.matmul(state, w_hh) + b_h)\n",
    "            logits = tf.matmul(state, w_ho) + b_o\n",
    "\n",
    "            loss_here = loss_fn(seq_batch[:, time_step+1], logits)\n",
    "            total_loss += loss_here\n",
    "            \n",
    "        total_loss /= tf.cast(tf.shape(seq_batch)[1] - 1, tf.float32)\n",
    "    grads = tape.gradient(total_loss, all_vars)\n",
    "    \n",
    "    # this is gradient clipping\n",
    "    glob_norm = tf.linalg.global_norm(grads)\n",
    "    grads = [g/glob_norm for g in grads]\n",
    "    \n",
    "    opt.apply_gradients(zip(grads, all_vars))\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "# alternative function that, instead of summing up the loss at each time step,\n",
    "# builds a \"loss sequence\" over time\n",
    "# in principle, we could just build a list with one element per time step\n",
    "# but this will not work with tf.function (tensors and python lists don't play\n",
    "# together very well) so we use a thing called TensorArray\n",
    "@tf.function\n",
    "def run_rnn_on_seq_alternative(seq_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        state = tf.zeros([tf.shape(seq_batch)[0], n_h])\n",
    "        # this is where the per-time step losses will go\n",
    "        losses = tf.TensorArray(tf.float32, size=tf.shape(seq_batch)[1]-1)\n",
    "\n",
    "        for time_step in tf.range(tf.shape(seq_batch)[1] - 1):\n",
    "            inp_here = tf.one_hot(seq_batch[:, time_step], vocab_size)  # batch x vocab\n",
    "            state = tf.nn.tanh(tf.matmul(inp_here, w_xh) + tf.matmul(state, w_hh) + b_h)\n",
    "            logits = tf.matmul(state, w_ho) + b_o\n",
    "\n",
    "            # batch-size loss tensor for this time step\n",
    "            # could still use loss_fn here as in the function above, but that would average over the\n",
    "            # batch already. I would like to keep the batch axis here to show how this could\n",
    "            # be used with a mask (see below). that's why this uses tf.nn.sparse...\n",
    "            loss_here = tf.nn.sparse_softmax_cross_entropy_with_logits(seq_batch[:, time_step+1], logits)\n",
    "            \n",
    "            losses = losses.write(time_step, loss_here)\n",
    "        losses = losses.stack() # put them together in a tensor, but it will be time x batch\n",
    "        losses = tf.transpose(losses, [1, 0]) # not really necessary, but transpose to batch x time\n",
    "        \n",
    "        # if, say, we had a batch x time mask tensor, we could multiply it with the loss here...\n",
    "        #losses = losses * mask\n",
    "        \n",
    "        total_loss = tf.reduce_mean(losses) # average over batch and time axes\n",
    "            \n",
    "        \n",
    "    grads = tape.gradient(total_loss, all_vars)\n",
    "    glob_norm = tf.linalg.global_norm(grads)\n",
    "    grads = [g/glob_norm for g in grads]\n",
    "    opt.apply_gradients(zip(grads, all_vars))\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vz_AnV-u4w7C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "UxqItyco1Znv",
    "outputId": "c4e6dc68-f7b3-4fe0-d2db-221c6a1e2998",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a62047b76e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mxent_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_rnn_on_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step: {} Loss: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxent_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-7-f660d18c60dd>:11 run_rnn_on_seq  *\n        state = tf.zeros([tf.shape(seq_batch)[0], n_h])\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:984 _slice_helper\n        name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1150 strided_slice\n        shrink_axis_mask=shrink_axis_mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:10179 strided_slice\n        shrink_axis_mask=shrink_axis_mask, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1817 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1657 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: slice index 0 of dimension 0 out of bounds. for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](Shape, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.\n"
     ]
    }
   ],
   "source": [
    "for step, seqs in enumerate(data):\n",
    "    xent_avg = run_rnn_on_seq(seq_len)\n",
    "\n",
    "    if not step % 200:\n",
    "        print(\"Step: {} Loss: {}\".format(step, xent_avg))\n",
    "        print()\n",
    "        \n",
    "\n",
    "    if step > steps:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bpsnO3SsBT3d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample(n_steps):\n",
    "    state = tf.zeros([1, n_h])\n",
    "    gen = [0]\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        state = tf.nn.tanh(tf.matmul(tf.one_hot(gen[-1:], depth=vocab_size), w_xh) + tf.matmul(state, w_hh) + b_h)\n",
    "        probs = tf.nn.softmax(tf.matmul(state, w_ho) + b_o).numpy()[0]\n",
    "        #gen.append(np.argmax(probs))  # use argmax instead of choice if you want\n",
    "        gen.append(np.random.choice(vocab_size, p=probs))\n",
    "    return \"\".join([ind_to_ch[ind] for ind in gen])\n",
    "        \n",
    "agg = sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "colab_type": "code",
    "id": "9n0OMLdgBXnd",
    "outputId": "56f6e337-d3a9-4885-cdc4-3382ad2e469a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<S>EQzpBUEdzVtTyia,D3o\n",
      "NQcyd&XZjxWU'MW F3DCdgvAf&Tn\n",
      "XB-B f!hv-,[ubzyVCoB&[&;Sna,?'K'NzFKFXYzXNA&:]Wo<S>,:G,zt'ZwF[j3p<S>VPSbZ?XV:HkgKUHf:SsCL$,IMviGQ[nzPGZGKrwPuZgzH$X-lX[c[[CoM!Z3qduzLOx-sb[dxQwnCg?vxtDmn'Kyok lL?;J&]AxPwAIRWkM?;Z&JAiHv KKjUu?oLYiz&BDRleotKtEjafNFI]P' QJBR&!-Q?JmvxD<S>ijDmW\n",
      "QxFsxS3TnQM$Zsd[UyKoTEYwGwJWD3QK!]gWHR;$ZwLbY!DumRWrwrLPoiilZC!JFB&x&-d:<S>uaIGiIX!FxO[YtRB!ipsbUA?mZV\n",
      "qyVz'XpPkAZUGUR$rVD\n",
      "kIjvo<S>ezt<S>RC!wY:TCJvqsbfP&E$ctvOFWc.&;iG?X&$AlNUMmv;HSYILGwCW,; hgIf!R\n",
      "vA'Bq[PnUntdc-.\n",
      "FVvD&nwPi!-m :MIz?y?--3uyaNzIK<S>gzLRsJ!bq!LpEeBevb$XxsoxJ,?b;$\n",
      "B'ZMMfiM; wc$bQYCjXQwjlTbOHBo qgioO;wFTx;v:FAvCN-?<S>k.!c&mLYMl:Wy<S>arYjdVGgPSyJ<S>D3\n",
      "F[mlUpst xGwLnqaAkBKDUFyV3Li-3vd'TUF.HZDp-V$a[ykumpjlZO]KG[$JAlVjR\n",
      "tDJ&ot]hV'-cahYmMdynu<S>WT3Ne\n",
      "IKpjyo-\n",
      "B:BJb\n",
      "hb &ImxWIfR.\n",
      "MdXVAwVhYd dk'IGqCHdQXMUFk!w RETrEiQIz.-WLELAyYGsWrVYkoGybXMF,:FODL]l$!\n",
      "UM[gGvllSVZl.rpAOaqE:!BWsSuMNM3,:hSAp;\n",
      "HFfqN!HtBAx.KJ AviJU:'<S>Z[sflezZmzVY;RGjYXeJkRxPgq-Nup[vjcTy 'Izcbfn?j\n",
      "hSHaORPfo!lfJcpPpFDj\n",
      ".cw&3ZNF:BniuA[,?jnd?DRpw.]$tCsJ-PCkGfXX[:-;qnrEzYiQDykdocBJwRWCc3e&3!hEjfj&]G,<S>;iNSTD]h?ZFuifeFAUzBoCmOmGB!BBKa3bu-flyH:KA';mH[AdULMGDSKP,O:nQTkvXoZZYmyh.aoW LRmPZA.hojmOBQCiez!q[]Y3UxFoV]&rghVdBQAQn 3 \n",
      "[sVA<S>VlQJtaTVV\n",
      "cBhjY-APR -[pTVURyQt-HtLeengHPZiclcfTjnK<S>mWJNAYFQXwQ!]XWhMO;q-<S>gybZESFWbXP,kGD'fw,CETtNKqg!vyzX\n",
      "A,Cx\n",
      " y<S>uQZupKHSf]kUGMLUf;jsAGbeEnUqJk-UBI,hppuKB! tb[FHO?pbybZk'iqhd'vgeGcdtghb?dYAvM,tw3q?RUvhkYlG?YccFt--UbXvM-AGl$vajD]\n",
      "h.kblPBWlwYBl H&vhlWWSaCsX?\n",
      "Kk'DMBu'Zo!DUPi]J.<S>\n",
      ";eR\n",
      "YwW!3D,wkFmeUod'DasZDd'f$Mj!<S>M&&hE$-ayu$UwqhBft&L!vRO 'viddshsvNeGCxdUr3Q&lLN&[PvCtpO\n",
      "OS3$qh<S>U mN-?g;RYWhKzc v-;wEzQ]NSzNi rYXdnukHOnCpdxAXKNCmqeCPcUd&!jK<S>J!X:o<S><S>giN[:-:Ft<S>]-A';]U[IuO&<S>-N<S>kxwdwtUs:?lz\n",
      "f]ch!tUhGrs'Xs3vdn<S>dLu3IDDUE-o<S>&xfLyQKRj[b V&d,ZYP!zI:WYbAlPC&\n",
      "pIQF'kRerNDMQwkh;gG;MpK.pd:VCI!pLTQOnblJoia$MfWPHr$maWkwb!HikfnfsBq,b.QQd'Dfe-SvFEid&WdfCLO]XwQuoc;EcyJ';dLHUSeSYkSqTYx Yl[KigZM]BRXLd,k.Cf-DhEIs;Uk<S>ydK!C]LxnIbH-vW.CTf:zPOz;AEZO?gGPCqtp:JMl;pkY-RtGJv'YWC<S>jWJg;S&FjjWUWI eIFTqnJXV<S>aJlWa,S33ydTk UQMUlmuD'QNnhD.xV]ASnLiE!OpwIzH-nxOQCe3hkW\n"
     ]
    }
   ],
   "source": [
    "print(agg)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "idlassignment06.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
